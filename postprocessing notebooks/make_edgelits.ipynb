{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1c71a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:11.228236Z",
     "start_time": "2023-05-05T11:16:09.728283Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "path_data = \"../data/omn/\"\n",
    "path_data_maria = \"../data/omn/\"\n",
    "path_data_scenarios = \"../results/Data_out/results/\"\n",
    "path_fig = \"../results/figs/\"\n",
    "\n",
    "# Career changers\n",
    "# Related from here https://www.onetcenter.org/dictionary/27.0/excel/related_occupations.html\n",
    "# it's the updated version of Career Changers from my understanding, but diff classification system\n",
    "file_career_changers = \"Related Occupations.xlsx\"\n",
    "file_xwalk = \"soc_2010_to_2018_crosswalk.csv\"\n",
    "# census files\n",
    "file_edgelist = \"jb/edgelist_qualitycontrol_2011_2019_bls-9feb.csv\"\n",
    "\n",
    "# self loop value according to calculations following Lehm et al.\n",
    "occ_mobility = 0.06415\n",
    "self_loop = 1 - occ_mobility\n",
    "adjustment = 0.55\n",
    "\n",
    "start_year = 2021\n",
    "mark_year = 2034 # year marking the period split. Exclusive of mark year\n",
    "# for first period, inclusive for latter period. \n",
    "# i.e. mark_year is the start of second period\n",
    "end_year = 2038#mark_year + time_until_mark#2048\n",
    "print(mark_year, end_year)\n",
    "\n",
    "shock_type = \"relbase\"\n",
    "file_arch = \"occ_archetypes_thresholds_\" + shock_type + \"_\" + str(mark_year) \\\n",
    "    + \"_\" + str(end_year) + \".csv\"\n",
    "\n",
    "archaetypes = ['Phase_out_r0.01', 'Permanent_boost_r0.01',\\\n",
    "    'Temporary_boost_r0.01', 'Late_boost_r0.01']\n",
    "\n",
    "####################\n",
    "# import archetypes\n",
    "###################\n",
    "df_shocks = pd.read_csv(path_data_maria + file_arch)\n",
    "shocks_soc = set(df_shocks[\"O*NET-SOC Code\"])\n",
    "\n",
    "# Number of related occupations considered\n",
    "n_top = 20\n",
    "##############\n",
    "# Career Changers / Related Occupations file\n",
    "##############\n",
    "df_cc_raw = pd.read_excel(path_data + file_career_changers)\n",
    "# focus on 6 digit\n",
    "df_cc_raw [\"O*NET-SOC Code\"] = df_cc_raw [\"O*NET-SOC Code\"].str.slice(stop=7)\n",
    "df_cc_raw [\"Related O*NET-SOC Code\"] = df_cc_raw [\"Related O*NET-SOC Code\"]\\\n",
    "    .str.slice(stop=7)\n",
    "# crosswalk to soc 2010\n",
    "df_xwalk = pd.read_csv(path_data + file_xwalk, sep=\";\")\n",
    "dict_soc18_soc10 = dict(zip(df_xwalk[\"2018 SOC Code\"],df_xwalk[\"2010 SOC Code\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_xwalk with df_cc_raw\n",
    "df_cc_raw = df_cc_raw.merge(df_xwalk, left_on=\"O*NET-SOC Code\", right_on=\"2018 SOC Code\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set O*NET-SOC Code to soc10\n",
    "df_cc_raw ['O*NET-SOC Code'] = df_cc_raw ['2010 SOC Code']\n",
    "# drop columns that are not needed\n",
    "df_cc_raw.drop(['2018 SOC Code', '2010 SOC Code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c6619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc_raw = df_cc_raw.merge(df_xwalk, left_on=\"Related O*NET-SOC Code\", right_on=\"2018 SOC Code\", how=\"left\")\n",
    "# set O*NET-SOC Code to soc10\n",
    "df_cc_raw ['Related O*NET-SOC Code'] = df_cc_raw ['2010 SOC Code']\n",
    "# drop columns that are not needed\n",
    "df_cc_raw.drop(['2018 SOC Code', '2010 SOC Code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bd3ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:11.929604Z",
     "start_time": "2023-05-05T11:16:11.899607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregating codes to match\n",
    "def map_socs_to_shock(x):\n",
    "    if x in shocks_soc:\n",
    "        return x\n",
    "    else:\n",
    "        try:\n",
    "            if x[:-1] + \"0\" in shocks_soc:\n",
    "                return x[:-1] + \"0\"\n",
    "            elif x[:-2] + \"00\" in shocks_soc:\n",
    "                return x[:-2] + \"00\"\n",
    "            elif x[:-3] + \"000\" in shocks_soc:\n",
    "                return x[:-3] + \"000\"\n",
    "            else:\n",
    "                return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "        \n",
    "df_cc_raw ['O*NET-SOC Code'] = df_cc_raw ['O*NET-SOC Code']\\\n",
    "    .apply(map_socs_to_shock)\n",
    "df_cc_raw ['Related O*NET-SOC Code'] = df_cc_raw ['Related O*NET-SOC Code']\\\n",
    "    .apply(map_socs_to_shock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb34a93a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:13.526606Z",
     "start_time": "2023-05-05T11:16:12.215604Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "len(df_cc_raw ['O*NET-SOC Code'].unique())\n",
    "\n",
    "# group edges\n",
    "df_grouped = df_cc_raw.groupby(['O*NET-SOC Code', 'Related O*NET-SOC Code'])\\\n",
    "    ['Index'].mean().reset_index()\n",
    "    \n",
    "idx = df_grouped.groupby(['O*NET-SOC Code'])['Index']\\\n",
    "    .nsmallest(n_top, keep='first').index.get_level_values(1)\n",
    "# start dataframe where to have both all edges and add node info such as shocks\n",
    "df_cc = df_grouped.loc[idx].set_index('O*NET-SOC Code')\\\n",
    "    .loc[df_grouped['O*NET-SOC Code'].drop_duplicates()].reset_index()\n",
    "# Remove realted occupations that are self loops (thees will be added later)\n",
    "df_cc = df_cc[df_cc['O*NET-SOC Code'] != df_cc['Related O*NET-SOC Code']]\n",
    "\n",
    "# get out degree\n",
    "values = df_cc['O*NET-SOC Code'].value_counts(dropna=False).keys().tolist()\n",
    "counts = df_cc['O*NET-SOC Code'].value_counts(dropna=False).tolist()\n",
    "value_dict = dict(zip(values, counts))\n",
    "df_cc['out_degree'] = df_cc['O*NET-SOC Code'].map(value_dict)\n",
    "# df_cc['out_degree'].unique() # array([10,  7,  9,  5,  8,  6])\n",
    "df_cc[\"trans_prob_cc\"] = occ_mobility * (1./df_cc[\"out_degree\"])\n",
    "\n",
    "cc_soc = set(df_cc[\"O*NET-SOC Code\"]).union(set(df_cc[\"Related O*NET-SOC Code\"]))\n",
    "len(cc_soc)\n",
    "\n",
    "\n",
    "# add self loops\n",
    "last_col = df_cc.index[-1]\n",
    "for i, soc in enumerate(cc_soc):\n",
    "    df_cc.loc[last_col +  i] = [soc, soc, np.nan, value_dict[soc], self_loop]\n",
    "    \n",
    "    \n",
    "########\n",
    "# Census data   \n",
    "########\n",
    "\n",
    "df = pd.read_csv(path_data + file_edgelist)\n",
    "\n",
    "df_edgelist = df\n",
    "# map shocks\n",
    "dict_soc_title = dict(zip(df_shocks['O*NET-SOC Code'], df_shocks[\"OCC_TITLE\"]))\n",
    "dict_soc_title = dict(zip(df_shocks['O*NET-SOC Code'], df_shocks[\"OCC_TITLE\"]))\n",
    "dict_soc_emp = dict(zip(df_shocks['O*NET-SOC Code'], df_shocks[\"TOT_EMP\"]))\n",
    "dict_soc_shock_before = dict(zip(df_shocks['O*NET-SOC Code'], \\\n",
    "    df_shocks[\"shock_before_\" + str(mark_year)]))\n",
    "dict_soc_shock_after = dict(zip(df_shocks['O*NET-SOC Code'], \\\n",
    "    df_shocks[\"shock_after_\" + str(mark_year)]))\n",
    "\n",
    "df_edgelist[\"transition_prob_BLS_ASECnorm\"] = \\\n",
    "    df_edgelist[\"transition_adj_networkers_BLS\"]\\\n",
    "        /df_edgelist[\"EMPOCCLY_unadj_BLS\"]\n",
    "\n",
    "df_edgelist[\"transition_prob_BLS_ASECnorm_in\"] = \\\n",
    "    df_edgelist[\"transition_adj_networkers_BLS\"]\\\n",
    "        /df_edgelist[\"EMPOCC_unadj_BLS\"]\n",
    "        \n",
    "### NOTE Since some occupations are dropped (Fishing etc), we need to \n",
    "# renomarlize\n",
    "\n",
    "print(\"check probs sum to one \", np.isclose(\\\n",
    "    df_edgelist.groupby(\"OCCLY_BLS\")[\"transition_prob_BLS_ASECnorm\"].sum(), 1)\\\n",
    "        .sum() ==  len(df_edgelist.groupby(\"OCCLY_BLS\")\\\n",
    "        [\"transition_prob_BLS_ASECnorm\"].sum()))\n",
    "\n",
    "print(\"check probs sum to one \", np.isclose(\\\n",
    "    df_edgelist.groupby(\"OCC_BLS\")[\"transition_prob_BLS_ASECnorm_in\"].sum(), 1)\\\n",
    "        .sum() ==  len(df_edgelist.groupby(\"OCC_BLS\")\\\n",
    "        [\"transition_prob_BLS_ASECnorm_in\"].sum()))\n",
    "\n",
    "dict_soc_outdeg = df_edgelist.groupby(\"OCCLY_BLS\")\\\n",
    "    [\"transition_prob_BLS_ASECnorm\"].sum().to_dict()\n",
    "\n",
    "dict_soc_indeg = df_edgelist.groupby(\"OCC_BLS\")\\\n",
    "    [\"transition_prob_BLS_ASECnorm_in\"].sum().to_dict()\n",
    "\n",
    "dict_soc_corr = {}\n",
    "for key, value in dict_soc_outdeg.items():\n",
    "    dict_soc_corr[key] = 1 + 1 - value\n",
    "    \n",
    "dict_soc_corr_in = {}\n",
    "for key, value in dict_soc_indeg.items():\n",
    "    dict_soc_corr_in[key] = 1 + 1 - value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_edgelist[\"corr\"] = df_edgelist[\"OCCLY_BLS\"].map(dict_soc_corr)\n",
    "df_edgelist[\"transition_prob_BLS_ASECnorm_corr\"] = \\\n",
    "    df_edgelist[\"transition_prob_BLS_ASECnorm\"]*df_edgelist[\"corr\"]\n",
    "\n",
    "df_edgelist[\"corr_in\"] = df_edgelist[\"OCC_BLS\"].map(dict_soc_corr)\n",
    "df_edgelist[\"transition_prob_BLS_ASECnorm_in_corr\"] = \\\n",
    "    df_edgelist[\"transition_prob_BLS_ASECnorm_in\"]*df_edgelist[\"corr_in\"]\n",
    "\n",
    "# print(\"check probs sum to one \", np.isclose(\\\n",
    "#     df_edgelist.groupby(\"OCCLY_BLS\")[\"transition_prob_BLS_ASECnorm\"].sum(), 1\\\n",
    "#         , rtol=0.01).sum() ==  len(df_edgelist.groupby(\"OCCLY_BLS\")\\\n",
    "#         [\"transition_prob_BLS_ASECnorm\"].sum()))\n",
    "\n",
    "print('not sum 1 (should be empty)', df_edgelist.groupby(\"OCCLY_BLS\")[\"transition_prob_BLS_ASECnorm_corr\"].sum()[~np.isclose(df_edgelist.\\\n",
    "    groupby(\"OCCLY_BLS\")[\"transition_prob_BLS_ASECnorm_corr\"].sum(), 1, rtol=0.01)]\n",
    ")\n",
    "\n",
    "print('not sum 1 (should be empty)', df_edgelist.groupby(\"OCC_BLS\")[\"transition_prob_BLS_ASECnorm_in_corr\"].sum()[~np.isclose(df_edgelist.\\\n",
    "    groupby(\"OCC_BLS\")[\"transition_prob_BLS_ASECnorm_in_corr\"].sum(), 1, rtol=0.01)]\n",
    ")\n",
    "\n",
    "set(df_edgelist['OCCLY_BLS'])\n",
    "set(df_cc['O*NET-SOC Code'])\n",
    "\n",
    "#### Merge\n",
    "\n",
    "df_edgelist = df_edgelist.drop(columns=['Unnamed: 0', 'OCC_ASEC', \\\n",
    "                                        'OCCLY_label_ASEC', 'OCC_label_ASEC', \\\n",
    "                                        'OCCLY_ASEC'])\n",
    "df_cc = df_cc.drop(columns=['Index'])\n",
    "\n",
    "df_cc = df_cc.rename({'O*NET-SOC Code': 'OCC_source', \\\n",
    "    'Related O*NET-SOC Code': 'OCC_target'}, axis='columns')\n",
    "df_edgelist = df_edgelist.rename({'OCCLY_BLS': 'OCC_source', \\\n",
    "    'OCC_BLS': 'OCC_target'}, axis='columns')\n",
    "    \n",
    "df_edgelist.columns\n",
    "\n",
    "df_mobility = df_edgelist[['OCC_source', 'OCC_target', \\\n",
    "    'transition_prob_BLS_ASECnorm_corr', 'transition_prob_BLS_ASECnorm_in_corr', 'OCC_TITLE_OCC',\n",
    "       'OCC_TITLE_OCCLY', 'EMPOCCLY_unadj_BLS', 'EMPOCC_unadj_BLS', \\\n",
    "           'TOT_EMP_OCC', 'A_MEAN_OCC', 'TOT_EMP_OCCLY' ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d91a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:17.828197Z",
     "start_time": "2023-05-05T11:16:13.830687Z"
    }
   },
   "outputs": [],
   "source": [
    "for occ in set(df_cc.OCC_target):\n",
    "    \n",
    "    prob_sum   = df_cc.loc[(df_cc.OCC_target == occ) & (df_cc.OCC_source != occ), 'trans_prob_cc'].sum()\n",
    "    prob_count = df_cc.loc[(df_cc.OCC_target == occ) & (df_cc.OCC_source != occ), 'trans_prob_cc'].count()\n",
    "    \n",
    "    df_cc.loc[(df_cc.OCC_target == occ) & (df_cc.OCC_source != occ), 'trans_prob_cc_in'] = prob_sum / prob_count\n",
    "    df_cc.loc[(df_cc.OCC_target == occ) & (df_cc.OCC_source == occ), 'trans_prob_cc_in'] = \\\n",
    "        df_cc.loc[(df_cc.OCC_target == occ) & (df_cc.OCC_source == occ), 'trans_prob_cc'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549748e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:18.300756Z",
     "start_time": "2023-05-05T11:16:18.113829Z"
    }
   },
   "outputs": [],
   "source": [
    "set(df_edgelist['OCC_source'])\n",
    "set(df_cc['OCC_source'])\n",
    "\n",
    "df_cc.to_csv(path_data + \"career_changers_mobility_edgelist.csv\",index=False)\n",
    "df_mobility.to_csv(path_data + \"asec_to_bls_mobility_edgelist.csv\",index=False)\n",
    "\n",
    "################\n",
    "## Make merger\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88026ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:18.624370Z",
     "start_time": "2023-05-05T11:16:18.579354Z"
    }
   },
   "outputs": [],
   "source": [
    "df_both = pd.merge(df_mobility, df_cc, how=\"outer\", \\\n",
    "    on=[\"OCC_source\", \"OCC_target\"], indicator=True)\n",
    "\n",
    "print('edges in cc', len(df_cc))\n",
    "print('edges in mobility', len(df_mobility))\n",
    "\n",
    "α = len(df_mobility)/(len(df_cc) +  len(df_mobility))\n",
    "\n",
    "# Joris added alpha_specific\n",
    "count_cc = df_both[df_both['trans_prob_cc'] > 0].groupby(\"OCC_source\")['trans_prob_cc'].count()\n",
    "count_omn = df_both[df_both['transition_prob_BLS_ASECnorm_corr'] > 0].groupby(\"OCC_source\")['transition_prob_BLS_ASECnorm_corr'].count()\n",
    "\n",
    "alpha_specific =  count_omn / (count_cc + count_omn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e245095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:18.937251Z",
     "start_time": "2023-05-05T11:16:18.891621Z"
    }
   },
   "outputs": [],
   "source": [
    "df_both['out_degree_both'] = df_both['OCC_source'].map(df_both[['OCC_source', 'OCC_target']].groupby(df_both.OCC_source).agg('nunique')['OCC_target'])\n",
    "df_both['in_degree_both'] = df_both['OCC_target'].map(df_both[['OCC_source', 'OCC_target']].groupby(df_both.OCC_target).agg('nunique')['OCC_source'])\n",
    "\n",
    "df_both['trans_unif_in'] = 1 / df_both['in_degree_both']\n",
    "df_both['trans_unif'] = 1 / df_both['out_degree_both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0dbe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b0a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:54.711305Z",
     "start_time": "2023-05-05T11:16:19.223003Z"
    }
   },
   "outputs": [],
   "source": [
    "df_both[\"_merge\"].value_counts()\n",
    "\n",
    "df_both['_merge'] = df_both['_merge'].astype(str)  # convert to string type\n",
    "df_both = df_both.fillna(0)  # fill missing values with 0\n",
    "\n",
    "df_both.loc[df_both[\"OCC_source\"] == '39-1010'][\"transition_prob_BLS_ASECnorm_corr\"].sum()\n",
    "df_both.loc[df_both[\"OCC_source\"] == '39-1010'][\"trans_prob_cc\"].sum()\n",
    "df_both.loc[df_both[\"OCC_source\"] == \"11-1010\"][\"trans_prob_cc\"].sum()\n",
    "df_both.loc[df_both[\"OCC_source\"] == \"11-1010\"][\"transition_prob_BLS_ASECnorm_corr\"].sum()\n",
    "\n",
    "dict_soc_zerocc = df_both.groupby(\"OCC_source\")['trans_prob_cc']\\\n",
    "    .sum().to_dict()\n",
    "dict_soc_zeromobility = df_both.groupby(\"OCC_source\")\\\n",
    "    ['transition_prob_BLS_ASECnorm_corr'].sum().to_dict()\n",
    "\n",
    "dict_soc_zerocc_in = df_both.groupby(\"OCC_target\")['trans_prob_cc']\\\n",
    "    .sum().to_dict()\n",
    "dict_soc_zeromobility_in = df_both.groupby(\"OCC_target\")\\\n",
    "    ['transition_prob_BLS_ASECnorm_in_corr'].sum().to_dict()\n",
    "\n",
    "for index, row in df_both.iterrows():\n",
    "    # if both are above 0 use normal mix\n",
    "    if (dict_soc_zerocc[row[\"OCC_source\"]] > 0) & (dict_soc_zeromobility[row[\"OCC_source\"]] > 0):\n",
    "        df_both.at[index, \"trans_merge_alphaweight_spec\"] = alpha_specific.loc[row.OCC_source] * \\\n",
    "                row[\"transition_prob_BLS_ASECnorm_corr\"] + (1 - alpha_specific.loc[row.OCC_source]) * \\\n",
    "                row[\"trans_prob_cc\"]\n",
    "    elif dict_soc_zerocc[row[\"OCC_source\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight_spec\"] = row[\"transition_prob_BLS_ASECnorm_corr\"]\n",
    "    elif dict_soc_zeromobility[row[\"OCC_source\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight\"] =  row[\"trans_prob_cc\"]\n",
    "        \n",
    "for index, row in df_both.iterrows():\n",
    "    # if both are above 0 use normal mix\n",
    "    if (dict_soc_zerocc_in[row[\"OCC_target\"]] > 0) & (dict_soc_zeromobility_in[row[\"OCC_target\"]] > 0):\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in_spec\"] = alpha_specific.loc[row.OCC_target] * \\\n",
    "                row[\"transition_prob_BLS_ASECnorm_in_corr\"] + (1 - alpha_specific.loc[row.OCC_target]) * \\\n",
    "                row[\"trans_prob_cc_in\"]\n",
    "    elif dict_soc_zerocc_in[row[\"OCC_target\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in_spec\"] = row[\"transition_prob_BLS_ASECnorm_in_corr\"]\n",
    "    elif dict_soc_zeromobility_in[row[\"OCC_target\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in_spec\"] =  row[\"trans_prob_cc_in\"]\n",
    "        \n",
    "for index, row in df_both.iterrows():\n",
    "    # if both are above 0 use normal mix\n",
    "    if (dict_soc_zerocc[row[\"OCC_source\"]] > 0) & (dict_soc_zeromobility[row[\"OCC_source\"]] > 0) & \\\n",
    "        (count_omn[row['OCC_source']] > 3):\n",
    "        df_both.at[index, \"trans_merge_alphaweight_spec_plus3\"] = alpha_specific.loc[row.OCC_source] * \\\n",
    "                row[\"transition_prob_BLS_ASECnorm_corr\"] + (1 - alpha_specific.loc[row.OCC_source]) * \\\n",
    "                row[\"trans_prob_cc\"]\n",
    "    elif dict_soc_zerocc[row[\"OCC_source\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight_spec_plus3\"] = row[\"transition_prob_BLS_ASECnorm_corr\"]\n",
    "    elif (dict_soc_zeromobility[row[\"OCC_source\"]] == 0) | (count_omn[row['OCC_source']] <= 3):\n",
    "        df_both.at[index, \"trans_merge_alphaweight_spec_plus3\"] =  row[\"trans_prob_cc\"]\n",
    "        \n",
    "for index, row in df_both.iterrows():\n",
    "    # if both are above 0 use normal mix\n",
    "    if (dict_soc_zerocc_in[row[\"OCC_target\"]] > 0) & (dict_soc_zeromobility_in[row[\"OCC_target\"]] > 0) & \\\n",
    "        (count_omn[row['OCC_target']] > 3):\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in_spec_plus3\"] = alpha_specific.loc[row.OCC_target] * \\\n",
    "                row[\"transition_prob_BLS_ASECnorm_in_corr\"] + (1 - alpha_specific.loc[row.OCC_target]) * \\\n",
    "                row[\"trans_prob_cc_in\"]\n",
    "    elif dict_soc_zerocc_in[row[\"OCC_target\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in_spec_plus3\"] = row[\"transition_prob_BLS_ASECnorm_in_corr\"]\n",
    "    elif (dict_soc_zeromobility_in[row[\"OCC_target\"]] == 0) | (count_omn[row['OCC_target']] <= 3):\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in_spec_plus3\"] =  row[\"trans_prob_cc_in\"]\n",
    "\n",
    "α = len(df_mobility)/(len(df_cc) +  len(df_mobility))\n",
    "for index, row in df_both.iterrows():\n",
    "    # if both are above 0 use normal mix\n",
    "    if (dict_soc_zerocc[row[\"OCC_source\"]] > 0) & (dict_soc_zeromobility[row[\"OCC_source\"]] > 0):\n",
    "        df_both.at[index, \"trans_merge_alphaweight\"] = α * row[\"transition_prob_BLS_ASECnorm_corr\"] + (1 - α) * row[\"trans_prob_cc\"]\n",
    "    elif dict_soc_zerocc[row[\"OCC_source\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight\"] = row[\"transition_prob_BLS_ASECnorm_corr\"]\n",
    "    elif dict_soc_zeromobility[row[\"OCC_source\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight\"] =  row[\"trans_prob_cc\"]\n",
    "        \n",
    "α = len(df_mobility)/(len(df_cc) +  len(df_mobility))\n",
    "for index, row in df_both.iterrows():\n",
    "    # if both are above 0 use normal mix\n",
    "    if (dict_soc_zerocc[row[\"OCC_target\"]] > 0) & (dict_soc_zeromobility[row[\"OCC_target\"]] > 0):\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in\"] = α * row[\"transition_prob_BLS_ASECnorm_in_corr\"] + (1 - α) * row[\"trans_prob_cc_in\"]\n",
    "    elif dict_soc_zerocc[row[\"OCC_target\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in\"] = row[\"transition_prob_BLS_ASECnorm_in_corr\"]\n",
    "    elif dict_soc_zeromobility[row[\"OCC_target\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alphaweight_in\"] =  row[\"trans_prob_cc_in\"]\n",
    "\n",
    "        \n",
    "α = 0.5\n",
    "for index, row in df_both.iterrows():\n",
    "    # if both are above 0 use normal mix\n",
    "    if (dict_soc_zerocc[row[\"OCC_source\"]] > 0) & (dict_soc_zeromobility[row[\"OCC_source\"]] > 0):\n",
    "        df_both.at[index, \"trans_merge_alpha05\"] = α * row[\"transition_prob_BLS_ASECnorm_corr\"] + (1 - α) * row[\"trans_prob_cc\"]\n",
    "    elif dict_soc_zerocc[row[\"OCC_source\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alpha05\"] = row[\"transition_prob_BLS_ASECnorm_corr\"]\n",
    "    elif dict_soc_zeromobility[row[\"OCC_source\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alpha05\"] =  row[\"trans_prob_cc\"]\n",
    "\n",
    "        \n",
    "for index, row in df_both.iterrows():\n",
    "    # if both are above 0 use normal mix\n",
    "    if (dict_soc_zerocc[row[\"OCC_target\"]] > 0) & (dict_soc_zeromobility[row[\"OCC_target\"]] > 0):\n",
    "        df_both.at[index, \"trans_merge_alpha05_in\"] = α * row[\"transition_prob_BLS_ASECnorm_in_corr\"] + (1 - α) * row[\"trans_prob_cc\"]\n",
    "    elif dict_soc_zerocc[row[\"OCC_target\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alpha05_in\"] = row[\"transition_prob_BLS_ASECnorm_in_corr\"]\n",
    "        #df_both.at[index, \"trans_prob_cc\"] =  row[\"transition_prob_BLS_ASECnorm_corr\"]\n",
    "    elif dict_soc_zeromobility[row[\"OCC_target\"]] == 0:\n",
    "        df_both.at[index, \"trans_merge_alpha05_in\"] =  row[\"trans_prob_cc\"]\n",
    "#     if dict_soc_zerocc[row[\"OCC_target\"]] == 0:\n",
    "#         df_both.at[index, \"trans_prob_cc\"] =  row[\"transition_prob_BLS_ASECnorm_in_corr\"]\n",
    "        \n",
    "df_both.groupby(\"OCC_source\")['trans_merge_alphaweight'].sum()[~np.isclose(df_both.groupby(\"OCC_source\")['trans_merge_alphaweight'].sum(), 1)]\n",
    "\n",
    "df_both.groupby(\"OCC_target\")['trans_merge_alphaweight_in'].sum()[~np.isclose(df_both.groupby(\"OCC_target\")['trans_merge_alphaweight_in'].sum(), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31668e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e7f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:56.039821Z",
     "start_time": "2023-05-05T11:16:55.091296Z"
    }
   },
   "outputs": [],
   "source": [
    "# add node data\n",
    "occ_title_occ_dict = df_mobility[['OCC_target', 'OCC_TITLE_OCC']].set_index('OCC_target')['OCC_TITLE_OCC'].to_dict()\n",
    "occ_emp_occ_dict = df_mobility[['OCC_target', 'TOT_EMP_OCC']].set_index('OCC_target')['TOT_EMP_OCC'].to_dict()\n",
    "a_mean_occ_dict = df_mobility[['OCC_target', 'A_MEAN_OCC']].set_index('OCC_target')['A_MEAN_OCC'].to_dict()\n",
    "\n",
    "df_both['OCC_TITLE_OCC'] = df_both.OCC_target.map(occ_title_occ_dict)\n",
    "df_both['OCC_TITLE_OCCLY'] = df_both.OCC_source.map(occ_title_occ_dict)\n",
    "df_both['TOT_EMP_OCC'] = df_both.OCC_target.map(occ_emp_occ_dict)\n",
    "df_both['TOT_EMP_OCCLY'] = df_both.OCC_source.map(occ_emp_occ_dict)\n",
    "df_both['A_MEAN_OCC'] = df_both.OCC_target.map(a_mean_occ_dict)\n",
    "\n",
    "\n",
    "df_mobility\n",
    "\n",
    "\n",
    "df_both.to_csv(path_data + \"edgelist_cc_mobility_merge.csv\",index=False)\n",
    "\n",
    "set(df_both['OCC_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58626c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:37:51.147190Z",
     "start_time": "2023-05-04T07:37:51.069192Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33c82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:56.494795Z",
     "start_time": "2023-05-05T11:16:56.450789Z"
    }
   },
   "outputs": [],
   "source": [
    "in_sum = df_both[~(df_both.OCC_source == df_both.OCC_target)]\\\n",
    "            [['OCC_target', 'trans_merge_alphaweight_in_spec_plus3']].\\\n",
    "            groupby('OCC_target').sum()\n",
    "\n",
    "in_sum[in_sum.trans_merge_alphaweight_in_spec_plus3 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a5a44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:56.905831Z",
     "start_time": "2023-05-05T11:16:56.892788Z"
    }
   },
   "outputs": [],
   "source": [
    "# I now impute these with trans_merge_alphaweight_in_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12d83b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:57.359829Z",
     "start_time": "2023-05-05T11:16:57.330784Z"
    }
   },
   "outputs": [],
   "source": [
    "df_both.loc[df_both.OCC_target == '43-5040', 'trans_merge_alphaweight_in_spec_plus3'] = \\\n",
    "        df_both.loc[df_both.OCC_target == '43-5040', 'trans_merge_alphaweight_in_spec']\n",
    "\n",
    "df_both.loc[df_both.OCC_target == '49-9095', 'trans_merge_alphaweight_in_spec_plus3'] = \\\n",
    "        df_both.loc[df_both.OCC_target == '49-9095', 'trans_merge_alphaweight_in_spec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98f96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ec467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:58.587783Z",
     "start_time": "2023-05-05T11:16:57.776785Z"
    }
   },
   "outputs": [],
   "source": [
    "df_both.to_csv(path_data + \"edgelist_cc_mobility_merge.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e6017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:58.967833Z",
     "start_time": "2023-05-05T11:16:58.922783Z"
    }
   },
   "outputs": [],
   "source": [
    "cc_sum = df_both[~(df_both.OCC_source == df_both.OCC_target)]\\\n",
    "            [['OCC_target', 'trans_prob_cc']].\\\n",
    "            groupby('OCC_target').sum()\n",
    "\n",
    "cc_sum[cc_sum.trans_prob_cc == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699d0ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:59.417784Z",
     "start_time": "2023-05-05T11:16:59.374787Z"
    }
   },
   "outputs": [],
   "source": [
    "cc_sum = df_both[~(df_both.OCC_source == df_both.OCC_target)]\\\n",
    "            [['OCC_source', 'trans_prob_cc']].\\\n",
    "            groupby('OCC_source').sum()\n",
    "\n",
    "cc_sum[cc_sum.trans_prob_cc == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973924eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:16:59.893784Z",
     "start_time": "2023-05-05T11:16:59.880784Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_cc = cc_sum[cc_sum.trans_prob_cc == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c99f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 'OCC_TITLE_OCCLY' in df_both for all missing_cc in OCC_source\n",
    "df_both[df_both.OCC_source.isin(missing_cc)][['OCC_source', 'OCC_TITLE_OCCLY']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56361c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:19:04.713931Z",
     "start_time": "2023-05-05T11:19:04.630266Z"
    }
   },
   "outputs": [],
   "source": [
    "for occ in cc_sum[cc_sum.trans_prob_cc == 0].index:\n",
    "    df_both.loc[df_both.OCC_source == occ, 'trans_prob_cc'] = \\\n",
    "        df_both.loc[df_both.OCC_source == occ, 'trans_unif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff574f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T11:19:05.750002Z",
     "start_time": "2023-05-05T11:19:05.242274Z"
    }
   },
   "outputs": [],
   "source": [
    "df_both.to_csv(path_data + \"edgelist_cc_mobility_merge.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a3646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T11:51:05.846183Z",
     "start_time": "2023-05-08T11:50:53.257791Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "path_data = \"../data/omn/\"\n",
    "# file that has before and after shocks\n",
    "file_arch = 'occ_archetypes_thresholds_relbase_2034_2038.csv'\n",
    "network_type = 'cc' #'uniform' #'baselinemerge' # 'cc' 'tasksim' #  # baseline is cc\n",
    "file_edgelist = 'edgelist_cc_mobility_merge.csv'\n",
    "path_fig = \"../results/figs/\"\n",
    "use_special_alpha = False\n",
    "use_separate_in_degree_normalisation = False\n",
    "cc_if_less_than_3 = False\n",
    "\n",
    "\n",
    "start_year = 2020\n",
    "mark_year = 2034 # year marking the period split. Exclusive of mark year\n",
    "# for first period, inclusive for latter period. \n",
    "end_year = 2038\n",
    "\n",
    "period_before = mark_year - start_year\n",
    "period_after = end_year - mark_year\n",
    "\n",
    "edge_weight = ''\n",
    "if network_type == \"baselinemerge\":\n",
    "    edge_weight = 'trans_merge_alphaweight'\n",
    "if network_type == 'cc':\n",
    "    edge_weight = 'trans_prob_cc'\n",
    "if network_type == 'tasksim':\n",
    "    edge_weight = 'Task_sim'\n",
    "if network_type == 'uniform':\n",
    "    edge_weight = 'trans_unif'\n",
    "\n",
    "\n",
    "file_export = 'occ_shock_network' + network_type+'_assortativity_flows.csv'\n",
    "\n",
    "# edgelist\n",
    "df_edgelist =  pd.read_csv(path_data + file_edgelist)\n",
    "df_nodes =  pd.read_csv(path_data + file_arch)\n",
    "\n",
    "shock_after_name = 'shock_after_' + str(mark_year)\n",
    "shock_before_name = 'shock_before_' + str(mark_year)\n",
    "# Add a normalized shock column\n",
    "df_nodes[shock_after_name +'_norm'] = df_nodes[shock_after_name] \\\n",
    "    / df_nodes['TOT_EMP']\n",
    "df_nodes[shock_before_name+'_norm'] = df_nodes[shock_before_name]\\\n",
    "    / df_nodes['TOT_EMP']\n",
    "# add log employment column\n",
    "df_nodes['TOT_EMP_log'] = np.log(df_nodes['TOT_EMP'])\n",
    "# Copy dataframe with less columns, used to plot\n",
    "df_occ = df_nodes[['O*NET-SOC Code', 'OCC_TITLE', 'TOT_EMP', 'A_MEAN',\\\n",
    "    'Phase_out_r0.01',  'Permanent_boost_r0.01', 'Temporary_boost_r0.01', \\\n",
    "    'Late_boost_r0.01', 'shock_after_2034', 'shock_before_2034', \\\n",
    "    'shock_after_2034_norm', 'shock_before_2034_norm', 'TOT_EMP_log']]\n",
    "\n",
    "# get dictionary of shocks and map to edgelist\n",
    "dict_occ_shock_bf = dict(zip(df_nodes['O*NET-SOC Code'], \\\n",
    "    df_nodes[shock_before_name]))\n",
    "\n",
    "dict_occ_shock_af = dict(zip(df_nodes['O*NET-SOC Code'], \\\n",
    "    df_nodes[shock_after_name ]))\n",
    "\n",
    "def make_dict_shock(shock=shock_after_name):\n",
    "    return dict(zip(df_nodes['O*NET-SOC Code'], df_nodes[shock]))\n",
    "\n",
    "def make_column_shock(df, shock=shock_after_name, direction='source'):\n",
    "    '''adds to the edgelist the shock of source or target occ repectively'''\n",
    "    \n",
    "    dict_occ_shock = make_dict_shock(shock)\n",
    "    df[shock +'_' + direction]  = df['OCC_' + direction].map(dict_occ_shock)\n",
    "        \n",
    "make_column_shock(df_edgelist, shock=shock_after_name, direction='source')\n",
    "make_column_shock(df_edgelist, shock=shock_before_name, direction='source')\n",
    "make_column_shock(df_edgelist, shock=shock_after_name, direction='target')\n",
    "make_column_shock(df_edgelist, shock=shock_before_name, direction='target')\n",
    "make_column_shock(df_edgelist, shock=shock_after_name+'_norm', direction\\\n",
    "    ='source')\n",
    "make_column_shock(df_edgelist, shock=shock_before_name+'_norm', direction\\\n",
    "    ='source')\n",
    "make_column_shock(df_edgelist, shock=shock_after_name+'_norm', direction\\\n",
    "    ='target')\n",
    "make_column_shock(df_edgelist, shock=shock_before_name+'_norm', direction\\\n",
    "    ='target')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Comands to get neigh average\n",
    "def make_df_shock_avneigh_shock(df, shock=shock_after_name, direction='in'):\n",
    "    ''' Computes the average shock of neighbors (in or out neightbors \n",
    "    depending on direction)\n",
    "    '''\n",
    "    spec_add = ''\n",
    "    in_add = ''\n",
    "    less_three_add = ''\n",
    "    if use_special_alpha == True:\n",
    "        spec_add = '_spec'\n",
    "    if cc_if_less_than_3 == True:\n",
    "        less_three_add = '_plus3'\n",
    "    if direction == 'in':\n",
    "        node = 'target'\n",
    "        neighbors = 'source'\n",
    "        if use_separate_in_degree_normalisation:\n",
    "            in_add = '_in'\n",
    "    elif direction == 'out':\n",
    "        node = 'source'\n",
    "        neighbors = 'target'\n",
    "       \n",
    "    # Remove self-loop so they aren't counted in average\n",
    "    df_temp = df[df['OCC_source'] != df['OCC_target']]\n",
    "    \n",
    "    # now group by node and take average over neigh weighted by edges\n",
    "    df_output = df_temp.groupby([\"OCC_\" + node]).apply(\\\n",
    "                lambda x:np.average(x[shock +'_' + neighbors], \\\n",
    "                    weights=x[edge_weight + in_add + spec_add + less_three_add])).reset_index()\n",
    "    \n",
    "    \n",
    "    df_output[\"node_shock\"] = df_output[\"OCC_\" + node]\\\n",
    "    .map(make_dict_shock(shock))\n",
    "    \n",
    "    df_output.rename(columns={0:'neighbors_shock'}, inplace=True)\n",
    "    \n",
    "    return df_output\n",
    "\n",
    "def make_dict_avneigh_shock(df, node):\n",
    "    '''Computes the average shock of neighbors and puts it in a\n",
    "    occ_avneigh shock dictionary\n",
    "    '''\n",
    "    dict_occ_neigh = dict(zip(df['OCC_' + node], df['neighbors_shock']))\n",
    "    \n",
    "    return dict_occ_neigh\n",
    "\n",
    "# Now without normalizing for shocks\n",
    "def make_df_shock_flow(df, shock=shock_after_name, direction='in'):\n",
    "    ''' Computes the expected (first other) flow given a shock\n",
    "    to occupations. \n",
    "    '''\n",
    "    if direction == 'in':\n",
    "        node = 'target'\n",
    "        neighbors = 'source'\n",
    "    elif direction == 'out':\n",
    "        node = 'source'\n",
    "        neighbors = 'target'\n",
    "       \n",
    "    # Remove self-loop so they aren't counted in average\n",
    "    df_temp = df[df['OCC_source'] != df['OCC_target']]\n",
    "    \n",
    "    # now group by node and take average over neigh weighted by edges\n",
    "    df_output = df_temp.groupby([\"OCC_\" + node]).apply(\\\n",
    "                lambda x:np.sum(x[shock +'_' + neighbors] * x[edge_weight]))\\\n",
    "                .reset_index()\n",
    "    \n",
    "    df_output[\"node_shock\"] = df_output[\"OCC_\" + node]\\\n",
    "    .map(make_dict_shock(shock))\n",
    "    \n",
    "    df_output.rename(columns={0:'flow_shock'}, inplace=True)\n",
    "    \n",
    "    return df_output\n",
    "\n",
    "\n",
    " # Now considering transition prob is yearly, account for period\n",
    "def make_df_shock_flow(df, shock=shock_after_name, direction='in'):\n",
    "    ''' Computes the expected (first other) flow given a shock\n",
    "    to occupations. \n",
    "    '''\n",
    "    if direction == 'in':\n",
    "        node = 'target'\n",
    "        neighbors = 'source'\n",
    "    elif direction == 'out':\n",
    "        node = 'source'\n",
    "        neighbors = 'target'\n",
    "        \n",
    "    if shock[6:8] == \"be\":\n",
    "        period = period_before\n",
    "    elif shock[6:8] == \"af\":\n",
    "        period = period_after\n",
    "       \n",
    "    # Remove self-loop so they aren't counted in average\n",
    "    df_temp = df[df['OCC_source'] != df['OCC_target']]\n",
    "    \n",
    "    # now group by node and take average over neigh weighted by edges\n",
    "    df_output = df_temp.groupby([\"OCC_\" + node]).apply(\\\n",
    "                lambda x:np.sum(x[shock +'_' + neighbors] * \\\n",
    "                    x[edge_weight] * period_before))\\\n",
    "                .reset_index()\n",
    "    \n",
    "    df_output[\"node_shock\"] = df_output[\"OCC_\" + node]\\\n",
    "    .map(make_dict_shock(shock))\n",
    "    \n",
    "    df_output.rename(columns={0:'flow_shock'}, inplace=True)\n",
    "    \n",
    "    return df_output\n",
    "\n",
    " \n",
    "\n",
    "def make_dict_flow_shock(df, node):\n",
    "    '''Computes  the expected (first other) flow given a shock and puts it in a\n",
    "    occ_avneigh shock dictionary\n",
    "    '''\n",
    "    dict_occ_neigh = dict(zip(df['OCC_' + node], df['flow_shock']))\n",
    "    \n",
    "    return dict_occ_neigh\n",
    "\n",
    "# Now without normalizing for shocks\n",
    "def make_df_shock_pool(df, shock=shock_after_name, direction='in'):\n",
    "    ''' Computes the expected (first other) pool shock given a shock\n",
    "    to occupations. \n",
    "    '''\n",
    "    if direction == 'in':\n",
    "        node = 'target'\n",
    "        neighbors = 'source'\n",
    "    elif direction == 'out':\n",
    "        node = 'source'\n",
    "        neighbors = 'target'\n",
    "       \n",
    "    # Remove self-loop so they aren't counted in average\n",
    "    df_temp = df[df['OCC_source'] != df['OCC_target']]\n",
    "    \n",
    "    # only if edge_weight > 0\n",
    "    df_temp = df_temp[df_temp[edge_weight] > 0]\n",
    "    \n",
    "    \n",
    "    # now group by node and take average over neigh weighted by edges\n",
    "    df_temp[\"tot_emp_\" + neighbors] = df_temp[\"OCC_\" + neighbors]\\\n",
    "        .map(make_dict_shock('TOT_EMP'))    \n",
    "    \n",
    "    df_output = df_temp.groupby([\"OCC_\" + node]).apply(\\\n",
    "                lambda x:np.sum(x[shock +'_' + neighbors]) / (np.sum(x['tot_emp_' + neighbors])))\\\n",
    "                .reset_index()\n",
    "    \n",
    "    df_output[\"node_shock\"] = df_output[\"OCC_\" + node]\\\n",
    "    .map(make_dict_shock(shock))\n",
    "    \n",
    "    df_output.rename(columns={0:'pool_shock'}, inplace=True)\n",
    "        \n",
    "    return df_output\n",
    "\n",
    " \n",
    "\n",
    "def make_dict_pool_shock(df, node):\n",
    "    '''Computes  the expected (first other) flow given a shock and puts it in a\n",
    "    occ_avneigh shock dictionary\n",
    "    '''\n",
    "    dict_occ_neigh = dict(zip(df['OCC_' + node], df['pool_shock']))\n",
    "    \n",
    "    return dict_occ_neigh\n",
    "\n",
    "#### Get shock and average of neighbors\n",
    "\n",
    "directions = ['in', 'out']\n",
    "shock_time = ['before', 'after']\n",
    "norm_not_norm = ['', '_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64329a43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T11:51:24.538535Z",
     "start_time": "2023-05-08T11:51:24.523534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now without normalizing for shocks\n",
    "def make_df_shock_updown(df, shock=shock_after_name, direction='in'):\n",
    "    ''' Computes the expected (first other) pool shock given a shock\n",
    "    to occupations. \n",
    "    '''\n",
    "    if direction == 'in':\n",
    "        node = 'target'\n",
    "        neighbors = 'source'\n",
    "    elif direction == 'out':\n",
    "        node = 'source'\n",
    "        neighbors = 'target'\n",
    "       \n",
    "    # Remove self-loop so they aren't counted in average\n",
    "    df_temp = df[df['OCC_source'] != df['OCC_target']]\n",
    "    \n",
    "    # only if edge_weight > 0\n",
    "    df_temp = df_temp[df_temp[edge_weight] > 0]\n",
    "    \n",
    "    phaseout_neigh = df_temp.loc[df_temp['OCC_' + neighbors].isin(df_occ.loc[df_occ['Phase_out_r0.01'] == 1, 'O*NET-SOC Code'])].groupby('OCC_' + node)['OCC_' + neighbors].count()\n",
    "    phaseout_neigh.name = 'n_phaseout'\n",
    "\n",
    "    temp_neigh = df_temp.loc[df_temp['OCC_' + neighbors].isin(df_occ.loc[df_occ['Temporary_boost_r0.01'] == 1, 'O*NET-SOC Code'])].groupby('OCC_' + node)['OCC_' + neighbors].count()\n",
    "    temp_neigh.name = 'n_temp'\n",
    "\n",
    "    perm_neigh = df_temp.loc[df_temp['OCC_' + neighbors].isin(df_occ.loc[df_occ['Permanent_boost_r0.01'] == 1, 'O*NET-SOC Code'])].groupby('OCC_' + node)['OCC_' + neighbors].count()\n",
    "    perm_neigh.name = 'n_perm'\n",
    "\n",
    "    neighs = df_temp.groupby('OCC_' + node)['OCC_' + neighbors].count()\n",
    "    neighs.name = 'n_neighs'\n",
    "\n",
    "    o = pd.concat([phaseout_neigh, temp_neigh, perm_neigh, neighs], axis=1).fillna(0)\n",
    "\n",
    "    if shock == shock_before_name:\n",
    "        o['updown_shock'] = (o.n_perm + o.n_temp - o.n_phaseout) / o.n_neighs\n",
    "    else:\n",
    "        o['updown_shock'] = (o.n_perm - o.n_temp - o.n_phaseout) / o.n_neighs\n",
    "\n",
    "    df_output = o[['updown_shock']].reset_index()\n",
    "    \n",
    "    \n",
    "    df_output[\"node_shock\"] = df_output[\"OCC_\" + node]\\\n",
    "    .map(make_dict_shock(shock))\n",
    "            \n",
    "    return df_output\n",
    "\n",
    " \n",
    "\n",
    "def make_dict_updown_shock(df, node):\n",
    "    '''Computes  the expected (first other) flow given a shock and puts it in a\n",
    "    occ_avneigh shock dictionary\n",
    "    '''\n",
    "    dict_occ_neigh = dict(zip(df['OCC_' + node], df['updown_shock']))\n",
    "    \n",
    "    return dict_occ_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23be046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbad626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T11:51:25.222960Z",
     "start_time": "2023-05-08T11:51:25.141968Z"
    }
   },
   "outputs": [],
   "source": [
    "df_edgelist[df_edgelist[edge_weight] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2596b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T11:51:27.057008Z",
     "start_time": "2023-05-08T11:51:25.524808Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# add neighbor shocks to df, vary between source, targe, before after, and norm\n",
    "for n in norm_not_norm:\n",
    "    for d in directions:\n",
    "        if d == 'in':\n",
    "            node = 'target'\n",
    "        elif d == 'out':\n",
    "            node = 'source'\n",
    "        for s in shock_time:\n",
    "            if s == 'before':\n",
    "                s_name = shock_before_name + n\n",
    "            else:\n",
    "                s_name = shock_after_name + n\n",
    "\n",
    "            # pool shock\n",
    "            df_temp = make_df_shock_pool(df_edgelist, \\\n",
    "                shock=s_name, direction=d)\n",
    "            dict_occ_neigh = make_dict_pool_shock(df_temp, node)\n",
    "            df_occ['pool_shock_' + d + s + n] = df_occ['O*NET-SOC Code']\\\n",
    "                .map(dict_occ_neigh)\n",
    "\n",
    "            \n",
    "            # fraction neighbours in up or down regime\n",
    "            df_temp = make_df_shock_updown(df_edgelist, \\\n",
    "                shock=s_name, direction=d)\n",
    "            dict_occ_neigh = make_dict_updown_shock(df_temp, node)\n",
    "            df_occ['frac_updown_' + d + s + n] = df_occ['O*NET-SOC Code']\\\n",
    "                .map(dict_occ_neigh)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e3df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T11:51:28.788007Z",
     "start_time": "2023-05-08T11:51:27.181058Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#####\n",
    "# Permanent boost analysis\n",
    "#####\n",
    "\n",
    "df_occ.to_csv(path_data + file_export, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
